# Scrape_with_Crawl4AI

## ğŸš€ Installation & Setup (2023 Edition)

### 1. Basic Installation

To install the core Crawl4AI library:

```bash
pip install crawl4ai
```

This installs the core **Crawl4AI** library along with essential dependencies.  
*Note: Advanced features (like transformers or PyTorch) are **not** included yet.*

---

### 2. Initial Setup & Diagnostics

#### 2.1 Run the Setup Command

After installing, run:

```bash
crawl4ai-setup
```

**What does it do?**

- Installs or updates required **Playwright browsers** (Chromium, Firefox, etc.)
- Performs **OS-level checks** (e.g., missing libs on Linux)
- Confirms your environment is **ready to crawl**

---

#### 2.2 Diagnostics (Optional)

You can run diagnostics to confirm everything is functioning properly:

```bash
crawl4ai-doctor
```

**This command attempts to:**

- Check **Python version compatibility**
- Verify **Playwright installation**
- Inspect **environment variables** or library conflicts

> âš ï¸ If any issues arise, follow the suggestions (e.g., installing additional system packages), then re-run `crawl4ai-setup`.

---

### 3. Verifying Installation: A Simple Crawl  
(*Skip this step if you've already run `crawl4ai-doctor`*)

Below is a minimal Python script that demonstrates a basic crawl using `BrowserConfig` and `CrawlerRunConfig`:

```python
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://www.example.com",
        )
        print(result.markdown[:300])  # Show the first 300 characters of extracted text

if __name__ == "__main__":
    asyncio.run(main())
```

**Expected Outcome:**

- A headless browser session loads `example.com`
- Crawl4AI returns ~300 characters of markdown

> â— If errors occur, re-run `crawl4ai-doctor` or manually ensure **Playwright** is installed correctly.

---
